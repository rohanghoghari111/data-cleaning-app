# ğŸ§¹ Universal Logical Data Cleaning Pipeline

**Industry-Grade, Reusable & Scalable Data Cleaning Framework (Pandas-Based)**

This project provides a **production-ready data cleaning pipeline** designed for real-world datasets (CSV, Excel, Pandas DataFrames). It is suitable for analytics, machine learning preprocessing, research datasets, ETL workflows, and dashboard applications (Streamlit, FastAPI, etc.).

---

## ğŸš€ Key Highlights

* âœ… **Universal Cleaner** â€“ Works without dataset-specific hardcoding
* âœ… **Logical Validation** â€“ Automatically fixes unrealistic or invalid values
* âœ… **Null Normalization** â€“ Handles missing values using industry standards
* âœ… **Data Type Enforcement** â€“ Ensures consistent numeric, categorical, and date types
* âœ… **Business Logic Enforcement** â€“ Automatically computes derived fields (e.g., profit)
* âœ… **Reusable Module** â€“ `utils.py` is fully plug-and-play
* âœ… **Future-Proof Pandas Usage** â€“ Avoids deprecated and unsafe operations

---

## ğŸ“ Project Structure

```
project-root/
â”‚
â”œâ”€â”€ app.py          # Entry point / application usage
â”œâ”€â”€ utils.py        # Core data cleaning and validation logic
â””â”€â”€ README.md       # Project documentation
```

---

## ğŸ§  Design Philosophy

This pipeline goes beyond cosmetic cleaning.

It enforces:

* Logical correctness
* Statistical sanity
* Business consistency
* Machine-learning-ready formatting

The goal is **trustworthy data**, not just clean-looking data.

---

## ğŸ”§ Core Components Explained

### 1ï¸âƒ£ Textual Null Normalization

Real-world datasets represent missing values in many forms.

Handled values include:

* `""`, `" "`, `"nan"`, `"NaN"`, `"NULL"`, `"None"`, `"undefined"`, `"-"`

All such values are normalized to **`np.nan`**, ensuring a single, reliable missing-value representation.

---

### 2ï¸âƒ£ Whitespace & Noise Cleaning

* Removes leading and trailing spaces
* Collapses multiple internal spaces into one
* Converts accidental string values like `"nan"` back to actual NaN

Result: clean, comparable string columns.

---

### 3ï¸âƒ£ Text Standardization

* All textual columns are converted to **Title Case**
* Exception: `certificate` column (handled separately)
* Mapping-based spelling corrections are applied

Examples:

* `Amazom Prime` â†’ `Amazon Prime`
* `Zee 5` â†’ `Zee5`
* `Indai` â†’ `India`

---

### 4ï¸âƒ£ Certificate Validation (Rule-Based)

Allowed values:

* `U`, `UA`, `A`

Any invalid or unexpected value is automatically set to `NaN`.

This ensures regulatory and categorical consistency.

---

### 5ï¸âƒ£ Numeric Conversion & Validation

Safely converts and validates the following columns (if present):

* `release_year`
* `duration_min`
* `imdb_rating`
* `budget_cr`
* `box_office_cr`
* `profit_cr`

**Validation Rules:**

* Release year must be between `1800` and `current_year + 1`
* IMDb rating must be between `0` and `10`
* Duration must be positive
* Budget and box office values must be non-negative

Invalid values are converted to `NaN` and logically imputed (median where appropriate).

---

### 6ï¸âƒ£ Date Handling

Recognized date columns:

* `order_date`
* `Order Date`

Dates are converted using:

```
pd.to_datetime(errors="coerce")
```

Invalid dates are safely ignored without raising exceptions.

---

### 7ï¸âƒ£ Business Logic Enforcement

When both columns are present:

```
profit_cr = box_office_cr - budget_cr
```

This guarantees consistency for derived business metrics.

---

### 8ï¸âƒ£ Final Data Type Enforcement

* `release_year` â†’ `Int64`
* `duration_min` â†’ `Int64`
* `imdb_rating` â†’ Rounded to 1 decimal place

This ensures compatibility with ML models, BI tools, and databases.

---

### 9ï¸âƒ£ Deduplication

* Removes exact duplicate rows
* Resets index after cleaning

Result: a clean and reliable dataset.

---

## ğŸ”„ Full Cleaning Pipeline

The `full_clean_pipeline(df)` function executes all steps in the correct order:

1. Normalize textual nulls
2. Clean whitespace
3. Standardize text fields
4. Convert and validate numeric columns
5. Convert date columns
6. Enforce business logic
7. Remove duplicate rows
8. Finalize data types

A single function call produces a **production-ready dataset**.

---

## ğŸ“Š Reporting Utilities

### Data Type Table

Returns a column-to-datatype mapping for schema audits and documentation.

### Cleaning Summary Report

Provides before-vs-after metrics for:

* Total missing values
* Duplicate row count

This improves transparency and explainability.

---

## ğŸ§ª Supported Use Cases

* Data science preprocessing
* Machine learning pipelines
* Research datasets
* Business analytics
* Streamlit dashboards
* ETL and data quality jobs

---

## âš™ï¸ Dependencies

* Python 3.9+
* pandas
* numpy

No heavy or unnecessary dependencies.

---

## ğŸ† Quality Standard

This is **not** a demo or tutorial-level cleaner.

âœ” Industry-grade
âœ” Research-safe
âœ” ML-ready
âœ” Scalable
âœ” Maintainable

---

## ğŸ“Œ Recommendation

Use `utils.py` as a **core data quality layer** in every analytics, ML, or data engineering project.

> "Bad data is more dangerous than no data." â€” This pipeline is designed to prevent that.

---

## ğŸ‘¨â€ğŸ’» Author Note

This pipeline is designed using real-world dirty datasets, not idealized examples.

It can be easily extended with additional validation rules, mappings, or integrated into any frontend or backend system.
